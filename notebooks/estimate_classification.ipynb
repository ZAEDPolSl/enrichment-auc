{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import f_oneway, tukey_hsd, ttest_1samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"Liver\"\n",
    "datatype = \"log2\" # \"raw_counts\"\n",
    "clustertype = \"kmeans\" # \"kmeans\"\n",
    "plottype = clustertype\n",
    "if clustertype != 'kmeans':\n",
    "    plottype = \"top1\"\n",
    "\n",
    "datafolder =  \"C:\\\\Users\\\\amruk\\\\source\\\\enrichment-auc\\\\data\\\\\"\n",
    "resfolder =  \"C:\\\\Users\\\\amruk\\\\source\\\\enrichment-auc\\\\results\\\\\"+dataset+\"\\\\\"+datatype+\"\\\\\"\n",
    "plotfolder =  \"C:\\\\Users\\\\amruk\\\\source\\\\enrichment-auc\\\\plots\\\\\"+dataset+\"\\\\\"+datatype+\"\\\\\"+plottype+\"\\\\\"+\"classification\\\\\"\n",
    "scorenames = [\"z\", \"gsva\", \"auc\", \"cerno\",\n",
    "              \"aucell\", \"vision\", \"ratios\",\n",
    "              \"svd\", \"sparse_pca\"]\n",
    "plot_scorenames = {\"AUCell\": \"aucell\",\n",
    "                   \"CERNO\": \"auc\",\n",
    "                   \"CERNO F\": \"cerno\",\n",
    "                   \"Vision\": \"vision\",\n",
    "                   \"z-score\": \"z\",\n",
    "                   \"DropRatio\": \"ratios\",\n",
    "                   \"PLAGE\": \"svd\",\n",
    "                   \"sparsPCA\": \"sparse_pca\",\n",
    "                   \"GSVA\": \"gsva\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Balanced_accuracy_\",\n",
    "        \"ARI_\",\n",
    "        \"F1_\",\n",
    "        \"Recall_\",\n",
    "        \"Matthews_\",\n",
    "        \"Jaccard_\",\n",
    "        \"Hamming_\",\n",
    "        \"Precision_\",\n",
    "        \"FDR_\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get chosen pathways for cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Category</th>\n",
       "      <th>Database</th>\n",
       "      <th>GSsize</th>\n",
       "      <th>GenesInGS</th>\n",
       "      <th>Perc</th>\n",
       "      <th>Celltype</th>\n",
       "      <th>Celltype_unclear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hsa04062</th>\n",
       "      <td>hsa04062</td>\n",
       "      <td>KEGG: Chemokine signaling pathway</td>\n",
       "      <td>KEGG: Organismal Systems; Immune system</td>\n",
       "      <td>KEGG</td>\n",
       "      <td>192</td>\n",
       "      <td>139</td>\n",
       "      <td>72.395833</td>\n",
       "      <td>T cell</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa04610</th>\n",
       "      <td>hsa04610</td>\n",
       "      <td>KEGG: Complement and coagulation cascades</td>\n",
       "      <td>KEGG: Organismal Systems; Immune system</td>\n",
       "      <td>KEGG</td>\n",
       "      <td>85</td>\n",
       "      <td>46</td>\n",
       "      <td>54.117647</td>\n",
       "      <td>B cell; T cell</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa04612</th>\n",
       "      <td>hsa04612</td>\n",
       "      <td>KEGG: Antigen processing and presentation</td>\n",
       "      <td>KEGG: Organismal Systems; Immune system</td>\n",
       "      <td>KEGG</td>\n",
       "      <td>78</td>\n",
       "      <td>66</td>\n",
       "      <td>84.615385</td>\n",
       "      <td>NK cell; T cell</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa04650</th>\n",
       "      <td>hsa04650</td>\n",
       "      <td>KEGG: Natural killer cell mediated cytotoxicity</td>\n",
       "      <td>KEGG: Organismal Systems; Immune system</td>\n",
       "      <td>KEGG</td>\n",
       "      <td>131</td>\n",
       "      <td>94</td>\n",
       "      <td>71.755725</td>\n",
       "      <td>NK cell</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa04657</th>\n",
       "      <td>hsa04657</td>\n",
       "      <td>KEGG: IL-17 signaling pathway</td>\n",
       "      <td>KEGG: Organismal Systems; Immune system</td>\n",
       "      <td>KEGG</td>\n",
       "      <td>94</td>\n",
       "      <td>63</td>\n",
       "      <td>67.021277</td>\n",
       "      <td>NK cell; T cell</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID                                            Title   \n",
       "hsa04062  hsa04062                KEGG: Chemokine signaling pathway  \\\n",
       "hsa04610  hsa04610        KEGG: Complement and coagulation cascades   \n",
       "hsa04612  hsa04612        KEGG: Antigen processing and presentation   \n",
       "hsa04650  hsa04650  KEGG: Natural killer cell mediated cytotoxicity   \n",
       "hsa04657  hsa04657                    KEGG: IL-17 signaling pathway   \n",
       "\n",
       "                                         Category Database  GSsize  GenesInGS   \n",
       "hsa04062  KEGG: Organismal Systems; Immune system     KEGG     192        139  \\\n",
       "hsa04610  KEGG: Organismal Systems; Immune system     KEGG      85         46   \n",
       "hsa04612  KEGG: Organismal Systems; Immune system     KEGG      78         66   \n",
       "hsa04650  KEGG: Organismal Systems; Immune system     KEGG     131         94   \n",
       "hsa04657  KEGG: Organismal Systems; Immune system     KEGG      94         63   \n",
       "\n",
       "               Perc         Celltype Celltype_unclear  \n",
       "hsa04062  72.395833           T cell               no  \n",
       "hsa04610  54.117647   B cell; T cell               no  \n",
       "hsa04612  84.615385  NK cell; T cell               no  \n",
       "hsa04650  71.755725          NK cell               no  \n",
       "hsa04657  67.021277  NK cell; T cell               no  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = pd.read_csv(datafolder+\"chosen_paths.txt\", sep='\\t', index_col=0)\n",
    "paths.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataset specific pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>source</th>\n",
       "      <th>DataBase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hsa04062</th>\n",
       "      <td>hsa04062</td>\n",
       "      <td>Chemokine signaling pathway</td>\n",
       "      <td>Organismal Systems; Immune system</td>\n",
       "      <td>KEGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa04610</th>\n",
       "      <td>hsa04610</td>\n",
       "      <td>Complement and coagulation cascades</td>\n",
       "      <td>Organismal Systems; Immune system</td>\n",
       "      <td>KEGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa04611</th>\n",
       "      <td>hsa04611</td>\n",
       "      <td>Platelet activation</td>\n",
       "      <td>Organismal Systems; Immune system</td>\n",
       "      <td>KEGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa04612</th>\n",
       "      <td>hsa04612</td>\n",
       "      <td>Antigen processing and presentation</td>\n",
       "      <td>Organismal Systems; Immune system</td>\n",
       "      <td>KEGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa04613</th>\n",
       "      <td>hsa04613</td>\n",
       "      <td>Neutrophil extracellular trap formation</td>\n",
       "      <td>Organismal Systems; Immune system</td>\n",
       "      <td>KEGG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID                                    Title   \n",
       "hsa04062  hsa04062              Chemokine signaling pathway  \\\n",
       "hsa04610  hsa04610      Complement and coagulation cascades   \n",
       "hsa04611  hsa04611                      Platelet activation   \n",
       "hsa04612  hsa04612      Antigen processing and presentation   \n",
       "hsa04613  hsa04613  Neutrophil extracellular trap formation   \n",
       "\n",
       "                                     source DataBase  \n",
       "hsa04062  Organismal Systems; Immune system     KEGG  \n",
       "hsa04610  Organismal Systems; Immune system     KEGG  \n",
       "hsa04611  Organismal Systems; Immune system     KEGG  \n",
       "hsa04612  Organismal Systems; Immune system     KEGG  \n",
       "hsa04613  Organismal Systems; Immune system     KEGG  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geneset_info = pd.read_csv(datafolder + dataset +\"//genesets_modules.csv\", index_col=0)\n",
    "geneset_info.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the ones in both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amruk\\AppData\\Local\\Temp\\ipykernel_20512\\2728621780.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_specific.Celltype = dataset_specific['Celltype'].str.replace(';',' +')\n"
     ]
    }
   ],
   "source": [
    "dataset_specific = paths[paths[\"ID\"].isin(geneset_info[\"ID\"])]\n",
    "dataset_specific.Celltype = dataset_specific['Celltype'].str.replace(';',' +')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save = dataset_specific[[\"ID\", \"Title\", \"Celltype\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Cell.type.authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SAMEA11294524-AAACCTGAGTCTCCTC</td>\n",
       "      <td>hepatocyte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SAMEA11294524-AAACCTGCAATGTAAG</td>\n",
       "      <td>monocyte-derived macrophage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SAMEA11294524-AAACCTGCACCGATAT</td>\n",
       "      <td>T cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SAMEA11294524-AAACCTGCAGTCAGAG</td>\n",
       "      <td>liver sinusoidal endothelial cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SAMEA11294524-AAACCTGGTATCAGTC</td>\n",
       "      <td>T cell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ID                  Cell.type.authors\n",
       "2  SAMEA11294524-AAACCTGAGTCTCCTC                         hepatocyte\n",
       "3  SAMEA11294524-AAACCTGCAATGTAAG        monocyte-derived macrophage\n",
       "4  SAMEA11294524-AAACCTGCACCGATAT                             T cell\n",
       "6  SAMEA11294524-AAACCTGCAGTCAGAG  liver sinusoidal endothelial cell\n",
       "7  SAMEA11294524-AAACCTGGTATCAGTC                             T cell"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels = pd.read_csv(datafolder + dataset +\"//true_labels.csv\", index_col=0)\n",
    "true_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels.set_index('NAME', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels.set_index('ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hepatocyte', 'monocyte-derived macrophage', 'T cell',\n",
       "       'liver sinusoidal endothelial cell', 'natural killer cell',\n",
       "       'cycling cell', 'plasma cell', 'B cell', 'cholangiocyte',\n",
       "       'Kupffer cell', 'vascular endothelial cell 1',\n",
       "       'vascular endothelial cell 2', 'activated HSC', 'quiescent HSC'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels = true_labels.rename(columns={'Cell.type.Ontology': 'CellType'})\n",
    "true_labels = true_labels.rename(columns={'Cell.type.authors': 'CellType'})\n",
    "true_labels.CellType.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_pre_B = ~true_labels[\"CellType\"].isin(['precursor B cell',\n",
    "                                                         'pro-B cell'])\n",
    "true_labels = true_labels[not_pre_B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['other', 'T cell', 'NK cell', 'B cell'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels.loc[true_labels[\"CellType\"].isin(['CD4+ T cell',\n",
    "                                              'Cytotoxic T cell']), \"CellType\"] = 'T cell'\n",
    "true_labels.loc[true_labels[\"CellType\"].isin(['mature B cell']), \"CellType\"] = 'B cell'\n",
    "true_labels.loc[true_labels[\"CellType\"].isin(['Natural killer cell', 'natural killer cell']), \"CellType\"] = 'NK cell'\n",
    "true_labels.loc[~true_labels[\"CellType\"].isin(['NK cell',\n",
    "                                               'T cell',\n",
    "                                               'B cell']), \"CellType\"] = 'other'\n",
    "true_labels.CellType.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate classification scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scores:\n",
    "    def __init__(self):\n",
    "        self.scoring_methods = [metrics.balanced_accuracy_score,\n",
    "                                metrics.adjusted_rand_score,\n",
    "                                metrics.f1_score,\n",
    "                                metrics.recall_score,\n",
    "                                metrics.matthews_corrcoef,\n",
    "                                metrics.jaccard_score,\n",
    "                                metrics.hamming_loss,\n",
    "                                metrics.precision_score\n",
    "                                ]\n",
    "        self.names = names\n",
    "        self.scores = [[] for _ in self.names]\n",
    "\n",
    "    def get_classification_scores(self, y_true, y_pred):\n",
    "        for i, scoring in enumerate(self.scoring_methods):\n",
    "            res = scoring(y_true, y_pred)\n",
    "            self.scores[i].append(res)\n",
    "        self.scores[-1].append(1-res)\n",
    "\n",
    "    def save_confusion_matrix(self, y_true, y_pred, resfolder, scorename, gs_name):\n",
    "        mx = metrics.confusion_matrix(y_true, y_pred)\n",
    "        df = pd.DataFrame(mx)\n",
    "        df.index.name = 'true label'\n",
    "        df.columns.name = 'predicted label'\n",
    "        df.to_csv(resfolder+\"confusion_matrix_\"+plottype+\"\\\\\"+gs_name+\"_\"+scorename+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save = to_save[to_save.Celltype.str.contains('|'.join(true_labels.CellType.unique()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amruk\\Miniconda3\\envs\\enrich\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for scorename in list(plot_scorenames.values()):\n",
    "    scores = pd.read_csv(resfolder+ scorename + \".csv\", index_col=0)\n",
    "    scores = scores.loc[:, not_pre_B]\n",
    "    thresholds = pd.read_csv(\n",
    "        resfolder+ scorename +\"_\" + clustertype + \"_thr\" \".csv\",\n",
    "        index_col=0)\n",
    "    eval = Scores()\n",
    "    for index, row in to_save.iterrows():\n",
    "        gs_score = scores.loc[row[\"ID\"]]\n",
    "        thr = thresholds.loc[row[\"ID\"]].max()\n",
    "        preds = gs_score > thr\n",
    "        preds = preds.astype(int)\n",
    "        true_labels[\"label\"] = true_labels.CellType.isin(\n",
    "            row[\"Celltype\"].split(\" + \")\n",
    "            ).astype(int)\n",
    "        eval.get_classification_scores(true_labels[\"label\"], preds)\n",
    "        eval.save_confusion_matrix(true_labels[\"label\"], preds,\n",
    "                                   resfolder, scorename, row[\"ID\"])\n",
    "    for i, cls_score in enumerate(eval.scores):\n",
    "        to_save.loc[:, eval.names[i]+scorename] = cls_score\n",
    "\n",
    "to_save.to_csv(resfolder+\"classification_scores_\"+plottype+\".csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_differences(df, name):\n",
    "    pval = f_oneway(*[list(df[name+sc_name]) for sc_name in list(plot_scorenames.values())]).pvalue\n",
    "    subtitle = \"<br>ANOVA p-value : {}\".format(np.round(pval, 3))\n",
    "    pvals = np.ones((len(list(plot_scorenames.values())), len(list(plot_scorenames.values()))))\n",
    "    if pval < 0.05:\n",
    "        pvals = tukey_hsd(*[list(df[name+sc_name]) for sc_name in list(plot_scorenames.values())]).pvalue\n",
    "        if pval < 0.001:\n",
    "            subtitle = \"<br>ANOVA p-value < 0.001\"\n",
    "    return pvals, subtitle\n",
    "\n",
    "\n",
    "def get_brackets(pvals):\n",
    "    dtype = [(\"start_idx\", int), (\"end_idx\", int), (\"dist\", int), (\"pvalue\", \"S10\")]\n",
    "    brackets = np.empty(0, dtype=dtype)\n",
    "    for i in range(pvals.shape[0]):\n",
    "        for j in range(i+1, pvals.shape[1]):\n",
    "            if pvals[i, j] <= 0.05:\n",
    "                text = str(np.round(pvals[i, j], 3))\n",
    "                if pvals[i, j] < 0.001:\n",
    "                    text = \"<0.001\"\n",
    "                bracket = (i,\n",
    "                           j,\n",
    "                           j-i,\n",
    "                           text)\n",
    "                bracket = np.array(bracket, dtype=dtype)\n",
    "                brackets = np.append(brackets, bracket)\n",
    "    brackets = np.sort(brackets, order=[\"dist\", \"start_idx\"])\n",
    "    return brackets\n",
    "\n",
    "\n",
    "def add_brackets(brackets, fig):\n",
    "    lower = 1.0\n",
    "    upper = 1.05\n",
    "    for bracket in brackets:\n",
    "        i = bracket[\"start_idx\"]\n",
    "        j = bracket[\"end_idx\"]\n",
    "        x = [list(plot_scorenames.keys())[i]] + list(plot_scorenames.keys())[i:j] + [list(plot_scorenames.keys())[j]]*2\n",
    "        y = [lower]+ [upper]*(j-i+1)+[lower]\n",
    "        fig.add_trace(go.Scatter(x=x,\n",
    "                                 y=y,\n",
    "                                 fill=None,\n",
    "                                 mode=\"lines\",\n",
    "                                 line=dict(color='rgba(0,0,0,1)', width=1),\n",
    "                                 showlegend=False\n",
    "                                 ))\n",
    "        fig.add_annotation(text=str(bracket[\"pvalue\"].decode('UTF-8')),\n",
    "                           name=\"p-value\",                                  \n",
    "                           x=(j+i)/2,\n",
    "                           y=upper+0.04,\n",
    "                           showarrow=False,\n",
    "                           font=dict(size=10, color=\"black\")\n",
    "                           )\n",
    "        lower = lower + 0.1\n",
    "        upper = upper + 0.1\n",
    "    return fig\n",
    "\n",
    "\n",
    "def mark_different_boxes(fig, pvals):\n",
    "    brackets = get_brackets(pvals)\n",
    "    fig = add_brackets(brackets, fig)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def visualize(df, cell_types, namescores, plot_folder):\n",
    "    for celltype in cell_types:\n",
    "        for name in namescores:\n",
    "            vis = df.loc[df[\"Celltype\"].isin([celltype]), df.columns.str.contains(name)]\n",
    "            pvals, subtitle = check_differences(vis, name)\n",
    "            vis.columns = vis.columns.str.replace(name, \"\")\n",
    "            vis = vis.melt()\n",
    "            vis = vis.rename(columns={'variable': 'method'})\n",
    "            vis[\"method\"] = vis[\"method\"].map({v: k for k, v in plot_scorenames.items()})\n",
    "            fig = px.box(vis, x=\"method\", y=\"value\", color=\"method\",\n",
    "                         title=celltype+subtitle,\n",
    "                         template=\"plotly_white\",\n",
    "                         labels={\"method\": \"PAS method\", \"value\": name[:-1].replace(\"_\", \" \")},\n",
    "                         category_orders={\"method\": list(plot_scorenames.keys())})\n",
    "            fig = mark_different_boxes(fig, pvals)\n",
    "            fig.update_xaxes(tickangle=45)\n",
    "            fig.write_image(plot_folder + celltype.replace(\" \", \"_\") + \"_\" + name[:-1] + \".png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_difference(df1, df2, namescores, plot_folder):\n",
    "    df = df1.subtract(df2)\n",
    "    for name in namescores:\n",
    "        vis = df.loc[:, df.columns.str.contains(name)]\n",
    "        vis.columns = vis.columns.str.replace(name, \"\")\n",
    "        vis = vis.melt()\n",
    "        vis = vis.rename(columns={'variable': 'method'})\n",
    "        vis[\"method\"] = vis[\"method\"].map({v: k for k, v in plot_scorenames.items()})\n",
    "        fig = px.box(vis, x=\"method\", y=\"value\", color=\"method\",\n",
    "                        title=name[:-1].replace(\"_\", \" \"),\n",
    "                        template=\"plotly_white\",\n",
    "                        labels={\"method\": \"PAS method\", \"value\": \"Difference [Top1 - k-means]\"},\n",
    "                        category_orders={\"method\": list(plot_scorenames.keys())})\n",
    "        fig.add_hline(y=0.0, line=dict(dash='dash', color = \"firebrick\", width = 1))\n",
    "        fig.update_xaxes(tickangle=45)\n",
    "        for score in list(plot_scorenames.keys()):\n",
    "            vals = vis.loc[vis[\"method\"]==score]\n",
    "            pval = ttest_1samp(vals[\"value\"], 0.0).pvalue\n",
    "            if pval < 0.05:\n",
    "                text = str(np.round(pval, 3))\n",
    "                if pval < 0.001:\n",
    "                    text = \"<0.001\"\n",
    "                y = vals[\"value\"].min()-0.05\n",
    "                if vals[\"value\"].mean() > 0:\n",
    "                    y = vals[\"value\"].max()+0.05\n",
    "                fig.add_annotation(text=text,\n",
    "                        name=\"p-value\",                                  \n",
    "                        x=score,\n",
    "                        y=y,\n",
    "                        showarrow=False,\n",
    "                        font=dict(size=10, color=\"red\")\n",
    "                        )\n",
    "        fig.add_annotation(text=\"Better Top1\",\n",
    "                           name=\"p-value\",                                  \n",
    "                           x=0.5,\n",
    "                           y=vis[\"value\"].max()+0.15,\n",
    "                           xref=\"paper\",\n",
    "                           showarrow=False,\n",
    "                           font=dict(size=12, color=\"black\")\n",
    "                           )\n",
    "        fig.add_annotation(text=\"Better k-means\",\n",
    "                           name=\"p-value\",                                  \n",
    "                           x=0.5,\n",
    "                           y=vis[\"value\"].min()-0.15,\n",
    "                           xref=\"paper\",\n",
    "                           showarrow=False,\n",
    "                           font=dict(size=12, color=\"black\")\n",
    "                           )\n",
    "        fig.write_image(plot_folder + \"difference_\" + name[:-1] + \".png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Celltype\n",
       "B cell              10\n",
       "B cell + T cell      1\n",
       "NK cell + T cell     2\n",
       "T cell              14\n",
       "Name: Celltype, dtype: int64"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotfolder =  \"C:\\\\Users\\\\amruk\\\\source\\\\enrichment-auc\\\\plots\\\\COVID\\\\\"+datatype+\"\\\\\"+plottype+\"\\\\\"+\"classification\\\\\"\n",
    "resfolder =  \"C:\\\\Users\\\\amruk\\\\source\\\\enrichment-auc\\\\results\\\\COVID\\\\\"+datatype+\"\\\\\"\n",
    "covid_df = pd.read_csv(resfolder+\"classification_scores_\"+plottype+\".csv\", index_col=0)\n",
    "groups = covid_df.groupby([\"Celltype\"])[\"Celltype\"].count()\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "celltypes = groups[groups > 2].keys().tolist()\n",
    "visualize(covid_df, celltypes, names, plotfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotfolder =  \"C:\\\\Users\\\\amruk\\\\source\\\\enrichment-auc\\\\plots\\\\COVID\\\\\"+datatype+\"\\\\\"\n",
    "resfolder =  \"C:\\\\Users\\\\amruk\\\\source\\\\enrichment-auc\\\\results\\\\COVID\\\\\"+datatype+\"\\\\\"\n",
    "covid_kmeans_df = pd.read_csv(resfolder+\"classification_scores_kmeans.csv\", index_col=0)\n",
    "covid_top1_df = pd.read_csv(resfolder+\"classification_scores_top1.csv\", index_col=0)\n",
    "\n",
    "cols = [\"ID\", \"Title\", \"Celltype\"]\n",
    "covid_top1_df.drop(columns=cols, inplace=True)\n",
    "covid_kmeans_df.drop(columns=cols, inplace=True)\n",
    "visualize_difference(covid_top1_df, covid_kmeans_df, names, plotfolder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Celltype\n",
       "B cell              9\n",
       "B cell + T cell     1\n",
       "NK cell             6\n",
       "NK cell + T cell    3\n",
       "Name: Celltype, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotfolder =  \"C:\\\\Users\\\\amruk\\\\source\\\\enrichment-auc\\\\plots\\\\BM\\\\\"+datatype+\"\\\\\"+plottype+\"\\\\\"+\"classification\\\\\"\n",
    "resfolder =  \"C:\\\\Users\\\\amruk\\\\source\\\\enrichment-auc\\\\results\\\\BM\\\\\"+datatype+\"\\\\\"\n",
    "bm_df = pd.read_csv(resfolder+\"classification_scores_\"+plottype+\".csv\", index_col=0)\n",
    "groups = bm_df.groupby([\"Celltype\"])[\"Celltype\"].count()\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celltypes = groups[groups > 2].keys().tolist()\n",
    "visualize(bm_df, celltypes, names, plotfolder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PBMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Celltype\n",
       "B cell              10\n",
       "B cell + T cell      1\n",
       "NK cell              7\n",
       "NK cell + T cell     4\n",
       "T cell              14\n",
       "Name: Celltype, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotfolder =  \"C:\\\\Users\\\\amruk\\\\source\\\\enrichment-auc\\\\plots\\\\PBMC\\\\\"+datatype+\"\\\\\"+plottype+\"\\\\\"+\"classification\\\\\"\n",
    "resfolder =  \"C:\\\\Users\\\\amruk\\\\source\\\\enrichment-auc\\\\results\\\\PBMC\\\\\"+datatype+\"\\\\\"\n",
    "pbmc_df = pd.read_csv(resfolder+\"classification_scores_\"+plottype+\".csv\", index_col=0)\n",
    "groups = pbmc_df.groupby([\"Celltype\"])[\"Celltype\"].count()\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celltypes = groups[groups > 2].keys().tolist()\n",
    "visualize(pbmc_df, celltypes, names, plotfolder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Liver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Celltype\n",
       "B cell              10\n",
       "B cell + T cell      1\n",
       "NK cell              6\n",
       "NK cell + T cell     4\n",
       "T cell              12\n",
       "Name: Celltype, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotfolder =  \"C:\\\\Users\\\\amruk\\\\source\\\\enrichment-auc\\\\plots\\\\Liver\\\\\"+datatype+\"\\\\\"+plottype+\"\\\\\"+\"classification\\\\\"\n",
    "resfolder =  \"C:\\\\Users\\\\amruk\\\\source\\\\enrichment-auc\\\\results\\\\Liver\\\\\"+datatype+\"\\\\\"\n",
    "liver_df = pd.read_csv(resfolder+\"classification_scores_\"+plottype+\".csv\", index_col=0)\n",
    "groups = liver_df.groupby([\"Celltype\"])[\"Celltype\"].count()\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "celltypes = groups[groups > 2].keys().tolist()\n",
    "visualize(liver_df, celltypes, names, plotfolder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Celltype\n",
       "B cell              39\n",
       "B cell + T cell      4\n",
       "NK cell             19\n",
       "NK cell + T cell    13\n",
       "T cell              40\n",
       "Name: Celltype, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotfolder =  \"C:\\\\Users\\\\amruk\\\\source\\\\enrichment-auc\\\\plots\\\\merged\\\\\"+datatype+\"\\\\\"+plottype+\"\\\\\"\n",
    "\n",
    "merged = pd.concat([covid_df, pbmc_df, liver_df, bm_df])\n",
    "groups = merged.groupby([\"Celltype\"])[\"Celltype\"].count()\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "celltypes = groups[groups > 2].keys().tolist()\n",
    "visualize(merged, celltypes, names, plotfolder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enrich",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
